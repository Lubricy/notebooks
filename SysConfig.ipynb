{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Forms",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/Lubricy/notebooks/blob/master/SysConfig.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "L2g6LyGMaUiT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "68176902-fb75-45e5-d960-e627303a97d1"
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.version"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.6.3 (default, Oct  3 2017, 21:45:48) \\n[GCC 7.2.0]'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "3jKM6GfzlgpS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e27a6703-b6dd-4478-e7e7-4a8ee6a996f6"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.test.is_gpu_available()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "bf5LUmgZt-kT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3075f2e5-83ee-451e-e6cf-326c481c983a"
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "\n",
        "def get_available_gpus():\n",
        "    local_device_protos = device_lib.list_local_devices()\n",
        "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
        "  \n",
        "get_available_gpus()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/device:GPU:0']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "aw5lgeRbubeF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ea483069-e0e1-494f-88dd-7e4714acf894"
      },
      "cell_type": "code",
      "source": [
        "!uname -a"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linux cc04dfb76cc0 4.14.33+ #1 SMP Wed Jun 20 01:36:48 PDT 2018 x86_64 x86_64 x86_64 GNU/Linux\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eFN7-fUKs-Bu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "0450ee74-7df9-42f8-e309-933e296db5de"
      },
      "cell_type": "code",
      "source": [
        "!lscpu"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Architecture:        x86_64\r\n",
            "CPU op-mode(s):      32-bit, 64-bit\r\n",
            "Byte Order:          Little Endian\r\n",
            "CPU(s):              2\r\n",
            "On-line CPU(s) list: 0,1\r\n",
            "Thread(s) per core:  2\r\n",
            "Core(s) per socket:  1\r\n",
            "Socket(s):           1\r\n",
            "NUMA node(s):        1\r\n",
            "Vendor ID:           GenuineIntel\r\n",
            "CPU family:          6\r\n",
            "Model:               63\r\n",
            "Model name:          Intel(R) Xeon(R) CPU @ 2.30GHz\r\n",
            "Stepping:            0\r\n",
            "CPU MHz:             2300.000\r\n",
            "BogoMIPS:            4600.00\r\n",
            "Hypervisor vendor:   KVM\r\n",
            "Virtualization type: full\r\n",
            "L1d cache:           32K\r\n",
            "L1i cache:           32K\r\n",
            "L2 cache:            256K\r\n",
            "L3 cache:            46080K\r\n",
            "NUMA node0 CPU(s):   0,1\r\n",
            "Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid pni pclmulqdq ssse3 fma cx16 sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm pti fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms xsaveopt\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ig8PIYeLtM8g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "ba156761-b516-48ab-a109-82532c98b1df"
      },
      "cell_type": "code",
      "source": [
        "!free -mh"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              total        used        free      shared  buff/cache   available\r\n",
            "Mem:            12G        1.1G        1.1G        250M         10G         11G\r\n",
            "Swap:            0B          0B          0B\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "h9aZYKhly2h_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "4d3f3fed-1c98-4ae9-ec6f-713f2ff867d7"
      },
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Jul 18 03:24:53 2018       \r\n",
            "+-----------------------------------------------------------------------------+\r\n",
            "| NVIDIA-SMI 384.111                Driver Version: 384.111                   |\r\n",
            "|-------------------------------+----------------------+----------------------+\r\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
            "|===============================+======================+======================|\r\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\r\n",
            "| N/A   38C    P0    70W / 149W |  10875MiB / 11439MiB |      0%      Default |\r\n",
            "+-------------------------------+----------------------+----------------------+\r\n",
            "                                                                               \r\n",
            "+-----------------------------------------------------------------------------+\r\n",
            "| Processes:                                                       GPU Memory |\r\n",
            "|  GPU       PID   Type   Process name                             Usage      |\r\n",
            "|=============================================================================|\r\n",
            "+-----------------------------------------------------------------------------+\r\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
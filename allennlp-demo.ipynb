{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Forms",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/Lubricy/notebooks/blob/master/allennlp-demo.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "h9aZYKhly2h_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/allenai/allennlp-as-a-library-example"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j_qv03kVnhch",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "53e1917b-b85a-4c17-960f-dd6c0d49fefd"
      },
      "cell_type": "code",
      "source": [
        "cd allennlp-as-a-library-example/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/allennlp-as-a-library-example\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XbqI3XaMoA2-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2638
        },
        "outputId": "f9131f49-bf56-4191-ab67-2f959dfefc0d"
      },
      "cell_type": "code",
      "source": [
        "!rm -r model\n",
        "!allennlp train experiments/venue_classifier.json -s model --include-package my_library"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\r\n",
            "  \"\"\")\r\n",
            "/usr/local/lib/python3.6/dist-packages/allennlp/service/predictors/__init__.py:24: FutureWarning: allennlp.service.predictors.* has been depreciated. Please use allennlp.predictors.*\r\n",
            "  \"Please use allennlp.predictors.*\", FutureWarning)\r\n",
            "/usr/local/lib/python3.6/dist-packages/allennlp/service/predictors/predictor.py:6: FutureWarning: allennlp.service.predictors.* has been deprecated. Please use allennlp.predictors.*\r\n",
            "  \" Please use allennlp.predictors.*\", FutureWarning)\n",
            "2018-07-18 04:45:27,997 - INFO - allennlp.common.params - random_seed = 13370\n",
            "2018-07-18 04:45:27,997 - INFO - allennlp.common.params - numpy_seed = 1337\n",
            "2018-07-18 04:45:27,997 - INFO - allennlp.common.params - pytorch_seed = 133\n",
            "2018-07-18 04:45:27,999 - INFO - allennlp.common.checks - Pytorch version: 0.4.0\n",
            "2018-07-18 04:45:28,001 - INFO - allennlp.common.params - dataset_reader.type = s2_papers\n",
            "2018-07-18 04:45:28,002 - INFO - allennlp.common.params - dataset_reader.lazy = False\n",
            "2018-07-18 04:45:28,002 - INFO - allennlp.common.params - dataset_reader.tokenizer.type = word\n",
            "2018-07-18 04:45:28,002 - INFO - allennlp.common.params - dataset_reader.tokenizer.word_splitter.type = spacy\n",
            "2018-07-18 04:45:28,002 - INFO - allennlp.common.params - dataset_reader.tokenizer.word_splitter.language = en_core_web_sm\n",
            "2018-07-18 04:45:28,002 - INFO - allennlp.common.params - dataset_reader.tokenizer.word_splitter.pos_tags = False\n",
            "2018-07-18 04:45:28,003 - INFO - allennlp.common.params - dataset_reader.tokenizer.word_splitter.parse = False\n",
            "2018-07-18 04:45:28,003 - INFO - allennlp.common.params - dataset_reader.tokenizer.word_splitter.ner = False\n",
            "2018-07-18 04:45:28,451 - INFO - allennlp.common.params - dataset_reader.tokenizer.word_filter.type = pass_through\n",
            "2018-07-18 04:45:28,451 - INFO - allennlp.common.params - dataset_reader.tokenizer.word_stemmer.type = pass_through\n",
            "2018-07-18 04:45:28,451 - INFO - allennlp.common.params - dataset_reader.tokenizer.start_tokens = None\n",
            "2018-07-18 04:45:28,451 - INFO - allennlp.common.params - dataset_reader.tokenizer.end_tokens = None\n",
            "2018-07-18 04:45:28,452 - INFO - allennlp.common.params - validation_dataset_reader = None\n",
            "2018-07-18 04:45:28,452 - INFO - allennlp.common.params - train_data_path = https://s3-us-west-2.amazonaws.com/allennlp/datasets/academic-papers-example/train.jsonl\n",
            "2018-07-18 04:45:28,452 - INFO - allennlp.commands.train - Reading training data from https://s3-us-west-2.amazonaws.com/allennlp/datasets/academic-papers-example/train.jsonl\n",
            "0it [00:00, ?it/s]2018-07-18 04:45:28,706 - INFO - my_library.dataset_readers.semantic_scholar_papers - Reading instances from lines in file at: https://s3-us-west-2.amazonaws.com/allennlp/datasets/academic-papers-example/train.jsonl\n",
            "491it [00:03, 146.78it/s]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000it [01:30, 166.28it/s]\n",
            "2018-07-18 04:46:58,666 - INFO - allennlp.common.params - validation_data_path = https://s3-us-west-2.amazonaws.com/allennlp/datasets/academic-papers-example/dev.jsonl\n",
            "2018-07-18 04:46:58,666 - INFO - allennlp.commands.train - Reading validation data from https://s3-us-west-2.amazonaws.com/allennlp/datasets/academic-papers-example/dev.jsonl\n",
            "0it [00:00, ?it/s]2018-07-18 04:46:58,896 - INFO - my_library.dataset_readers.semantic_scholar_papers - Reading instances from lines in file at: https://s3-us-west-2.amazonaws.com/allennlp/datasets/academic-papers-example/dev.jsonl\n",
            "2000it [00:11, 167.99it/s]\n",
            "2018-07-18 04:47:10,572 - INFO - allennlp.common.params - test_data_path = None\n",
            "2018-07-18 04:47:10,572 - INFO - allennlp.commands.train - Creating a vocabulary using validation, train data.\n",
            "2018-07-18 04:47:10,572 - INFO - allennlp.common.params - vocabulary.directory_path = None\n",
            "2018-07-18 04:47:10,573 - INFO - allennlp.common.params - vocabulary.min_count = None\n",
            "2018-07-18 04:47:10,573 - INFO - allennlp.common.params - vocabulary.max_vocab_size = None\n",
            "2018-07-18 04:47:10,573 - INFO - allennlp.common.params - vocabulary.non_padded_namespaces = ('*tags', '*labels')\n",
            "2018-07-18 04:47:10,573 - INFO - allennlp.common.params - vocabulary.only_include_pretrained_words = False\n",
            "2018-07-18 04:47:10,573 - INFO - allennlp.common.params - vocabulary.tokens_to_add = None\n",
            "2018-07-18 04:47:10,573 - INFO - allennlp.data.vocabulary - Fitting token dictionary from dataset.\n",
            "1267it [00:00, 2102.62it/s]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "17000it [00:07, 2132.38it/s]\n",
            "2018-07-18 04:47:18,923 - INFO - allennlp.common.params - model.type = paper_classifier\n",
            "2018-07-18 04:47:18,923 - INFO - allennlp.common.params - model.text_field_embedder.type = basic\n",
            "2018-07-18 04:47:18,923 - INFO - allennlp.common.params - model.text_field_embedder.embedder_to_indexer_map = None\n",
            "2018-07-18 04:47:18,924 - INFO - allennlp.common.params - model.text_field_embedder.tokens.type = embedding\n",
            "2018-07-18 04:47:18,924 - INFO - allennlp.common.params - model.text_field_embedder.tokens.num_embeddings = None\n",
            "2018-07-18 04:47:18,924 - INFO - allennlp.common.params - model.text_field_embedder.tokens.vocab_namespace = tokens\n",
            "2018-07-18 04:47:18,924 - INFO - allennlp.common.params - model.text_field_embedder.tokens.embedding_dim = 100\n",
            "2018-07-18 04:47:18,925 - INFO - allennlp.common.params - model.text_field_embedder.tokens.pretrained_file = https://s3-us-west-2.amazonaws.com/allennlp/datasets/glove/glove.6B.100d.txt.gz\n",
            "2018-07-18 04:47:18,925 - INFO - allennlp.common.params - model.text_field_embedder.tokens.projection_dim = None\n",
            "2018-07-18 04:47:18,925 - INFO - allennlp.common.params - model.text_field_embedder.tokens.trainable = False\n",
            "2018-07-18 04:47:18,925 - INFO - allennlp.common.params - model.text_field_embedder.tokens.padding_index = None\n",
            "2018-07-18 04:47:18,925 - INFO - allennlp.common.params - model.text_field_embedder.tokens.max_norm = None\n",
            "2018-07-18 04:47:18,926 - INFO - allennlp.common.params - model.text_field_embedder.tokens.norm_type = 2.0\n",
            "2018-07-18 04:47:18,926 - INFO - allennlp.common.params - model.text_field_embedder.tokens.scale_grad_by_freq = False\n",
            "2018-07-18 04:47:18,926 - INFO - allennlp.common.params - model.text_field_embedder.tokens.sparse = False\n",
            "2018-07-18 04:47:18,932 - INFO - allennlp.modules.token_embedders.embedding - Reading embeddings from file\n",
            "2018-07-18 04:47:26,467 - INFO - allennlp.modules.token_embedders.embedding - Initializing pre-trained embedding layer\n",
            "2018-07-18 04:47:26,824 - INFO - allennlp.common.params - model.title_encoder.type = lstm\n",
            "2018-07-18 04:47:26,824 - INFO - allennlp.common.params - model.title_encoder.batch_first = True\n",
            "2018-07-18 04:47:26,824 - INFO - allennlp.common.params - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n",
            "2018-07-18 04:47:26,825 - INFO - allennlp.common.params - CURRENTLY DEFINED PARAMETERS: \n",
            "2018-07-18 04:47:26,825 - INFO - allennlp.common.params - model.title_encoder.bidirectional = True\n",
            "2018-07-18 04:47:26,825 - INFO - allennlp.common.params - model.title_encoder.input_size = 100\n",
            "2018-07-18 04:47:26,825 - INFO - allennlp.common.params - model.title_encoder.hidden_size = 100\n",
            "2018-07-18 04:47:26,825 - INFO - allennlp.common.params - model.title_encoder.num_layers = 1\n",
            "2018-07-18 04:47:26,825 - INFO - allennlp.common.params - model.title_encoder.dropout = 0.2\n",
            "2018-07-18 04:47:26,826 - INFO - allennlp.common.params - model.title_encoder.batch_first = True\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:38: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "2018-07-18 04:47:26,829 - INFO - allennlp.common.params - model.abstract_encoder.type = lstm\n",
            "2018-07-18 04:47:26,829 - INFO - allennlp.common.params - model.abstract_encoder.batch_first = True\n",
            "2018-07-18 04:47:26,829 - INFO - allennlp.common.params - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n",
            "2018-07-18 04:47:26,829 - INFO - allennlp.common.params - CURRENTLY DEFINED PARAMETERS: \n",
            "2018-07-18 04:47:26,830 - INFO - allennlp.common.params - model.abstract_encoder.bidirectional = True\n",
            "2018-07-18 04:47:26,830 - INFO - allennlp.common.params - model.abstract_encoder.input_size = 100\n",
            "2018-07-18 04:47:26,830 - INFO - allennlp.common.params - model.abstract_encoder.hidden_size = 100\n",
            "2018-07-18 04:47:26,830 - INFO - allennlp.common.params - model.abstract_encoder.num_layers = 1\n",
            "2018-07-18 04:47:26,830 - INFO - allennlp.common.params - model.abstract_encoder.dropout = 0.2\n",
            "2018-07-18 04:47:26,830 - INFO - allennlp.common.params - model.abstract_encoder.batch_first = True\n",
            "2018-07-18 04:47:26,834 - INFO - allennlp.common.params - model.classifier_feedforward.input_dim = 400\n",
            "2018-07-18 04:47:26,834 - INFO - allennlp.common.params - model.classifier_feedforward.num_layers = 2\n",
            "2018-07-18 04:47:26,834 - INFO - allennlp.common.params - model.classifier_feedforward.hidden_dims = [200, 3]\n",
            "2018-07-18 04:47:26,835 - INFO - allennlp.common.params - model.classifier_feedforward.activations = ['relu', 'linear']\n",
            "2018-07-18 04:47:26,835 - INFO - allennlp.common.params - model.classifier_feedforward.dropout = [0.2, 0.0]\n",
            "2018-07-18 04:47:26,837 - INFO - allennlp.common.params - model.initializer = []\n",
            "2018-07-18 04:47:26,838 - INFO - allennlp.common.params - model.regularizer = []\n",
            "2018-07-18 04:47:26,838 - INFO - allennlp.nn.initializers - Initializing parameters\n",
            "2018-07-18 04:47:26,838 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
            "2018-07-18 04:47:26,839 - INFO - allennlp.nn.initializers -    abstract_encoder._module.bias_hh_l0\n",
            "2018-07-18 04:47:26,839 - INFO - allennlp.nn.initializers -    abstract_encoder._module.bias_hh_l0_reverse\n",
            "2018-07-18 04:47:26,839 - INFO - allennlp.nn.initializers -    abstract_encoder._module.bias_ih_l0\n",
            "2018-07-18 04:47:26,839 - INFO - allennlp.nn.initializers -    abstract_encoder._module.bias_ih_l0_reverse\n",
            "2018-07-18 04:47:26,839 - INFO - allennlp.nn.initializers -    abstract_encoder._module.weight_hh_l0\n",
            "2018-07-18 04:47:26,840 - INFO - allennlp.nn.initializers -    abstract_encoder._module.weight_hh_l0_reverse\n",
            "2018-07-18 04:47:26,840 - INFO - allennlp.nn.initializers -    abstract_encoder._module.weight_ih_l0\n",
            "2018-07-18 04:47:26,840 - INFO - allennlp.nn.initializers -    abstract_encoder._module.weight_ih_l0_reverse\n",
            "2018-07-18 04:47:26,840 - INFO - allennlp.nn.initializers -    classifier_feedforward._linear_layers.0.bias\n",
            "2018-07-18 04:47:26,840 - INFO - allennlp.nn.initializers -    classifier_feedforward._linear_layers.0.weight\n",
            "2018-07-18 04:47:26,840 - INFO - allennlp.nn.initializers -    classifier_feedforward._linear_layers.1.bias\n",
            "2018-07-18 04:47:26,841 - INFO - allennlp.nn.initializers -    classifier_feedforward._linear_layers.1.weight\n",
            "2018-07-18 04:47:26,841 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_tokens.weight\n",
            "2018-07-18 04:47:26,841 - INFO - allennlp.nn.initializers -    title_encoder._module.bias_hh_l0\n",
            "2018-07-18 04:47:26,841 - INFO - allennlp.nn.initializers -    title_encoder._module.bias_hh_l0_reverse\n",
            "2018-07-18 04:47:26,841 - INFO - allennlp.nn.initializers -    title_encoder._module.bias_ih_l0\n",
            "2018-07-18 04:47:26,842 - INFO - allennlp.nn.initializers -    title_encoder._module.bias_ih_l0_reverse\n",
            "2018-07-18 04:47:26,842 - INFO - allennlp.nn.initializers -    title_encoder._module.weight_hh_l0\n",
            "2018-07-18 04:47:26,842 - INFO - allennlp.nn.initializers -    title_encoder._module.weight_hh_l0_reverse\n",
            "2018-07-18 04:47:26,842 - INFO - allennlp.nn.initializers -    title_encoder._module.weight_ih_l0\n",
            "2018-07-18 04:47:26,842 - INFO - allennlp.nn.initializers -    title_encoder._module.weight_ih_l0_reverse\n",
            "2018-07-18 04:47:26,843 - INFO - allennlp.common.params - iterator.type = bucket\n",
            "2018-07-18 04:47:26,843 - INFO - allennlp.common.params - iterator.sorting_keys = [['abstract', 'num_tokens'], ['title', 'num_tokens']]\n",
            "2018-07-18 04:47:26,843 - INFO - allennlp.common.params - iterator.padding_noise = 0.1\n",
            "2018-07-18 04:47:26,843 - INFO - allennlp.common.params - iterator.biggest_batch_first = False\n",
            "2018-07-18 04:47:26,843 - INFO - allennlp.common.params - iterator.batch_size = 64\n",
            "2018-07-18 04:47:26,844 - INFO - allennlp.common.params - iterator.instances_per_epoch = None\n",
            "2018-07-18 04:47:26,844 - INFO - allennlp.common.params - iterator.max_instances_in_memory = None\n",
            "2018-07-18 04:47:26,844 - INFO - allennlp.common.params - trainer.patience = 10\n",
            "2018-07-18 04:47:26,844 - INFO - allennlp.common.params - trainer.validation_metric = +accuracy\n",
            "2018-07-18 04:47:26,845 - INFO - allennlp.common.params - trainer.num_epochs = 40\n",
            "2018-07-18 04:47:26,845 - INFO - allennlp.common.params - trainer.cuda_device = 0\n",
            "2018-07-18 04:47:26,845 - INFO - allennlp.common.params - trainer.grad_norm = None\n",
            "2018-07-18 04:47:26,845 - INFO - allennlp.common.params - trainer.grad_clipping = 5.0\n",
            "2018-07-18 04:47:26,845 - INFO - allennlp.common.params - trainer.learning_rate_scheduler = None\n",
            "2018-07-18 04:47:30,939 - INFO - allennlp.common.params - trainer.optimizer.type = adagrad\n",
            "2018-07-18 04:47:30,940 - INFO - allennlp.common.params - trainer.optimizer.parameter_groups = None\n",
            "2018-07-18 04:47:30,940 - INFO - allennlp.common.params - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n",
            "2018-07-18 04:47:30,940 - INFO - allennlp.common.params - CURRENTLY DEFINED PARAMETERS: \n",
            "2018-07-18 04:47:30,942 - INFO - allennlp.common.params - trainer.num_serialized_models_to_keep = None\n",
            "2018-07-18 04:47:30,942 - INFO - allennlp.common.params - trainer.keep_serialized_model_every_num_seconds = None\n",
            "2018-07-18 04:47:30,942 - INFO - allennlp.common.params - trainer.model_save_interval = None\n",
            "2018-07-18 04:47:30,943 - INFO - allennlp.common.params - trainer.summary_interval = 100\n",
            "2018-07-18 04:47:30,943 - INFO - allennlp.common.params - trainer.histogram_interval = None\n",
            "2018-07-18 04:47:30,948 - INFO - allennlp.common.params - evaluate_on_test = False\n",
            "2018-07-18 04:47:30,948 - INFO - allennlp.training.trainer - Beginning training.\n",
            "2018-07-18 04:47:30,949 - INFO - allennlp.training.trainer - Epoch 0/39\n",
            "2018-07-18 04:47:30,949 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 2900.896\n",
            "2018-07-18 04:47:31,044 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 350\n",
            "  0%|          | 0/235 [00:00<?, ?it/s]2018-07-18 04:47:31,046 - INFO - allennlp.training.trainer - Training\n",
            "accuracy: 0.3594, accuracy3: 1.0000, loss: 1.2025 ||:   2%|1         | 4/235 [00:11<10:47,  2.80s/it]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy: 0.6350, accuracy3: 1.0000, loss: 0.7839 ||: 100%|##########| 235/235 [00:35<00:00,  6.66it/s]\n",
            "2018-07-18 04:48:06,342 - INFO - allennlp.training.trainer - Validating\n",
            "accuracy: 0.7510, accuracy3: 1.0000, loss: 0.6077 ||: 100%|##########| 32/32 [00:03<00:00,  9.27it/s]\n",
            "2018-07-18 04:48:09,950 - INFO - allennlp.training.trainer - Best validation performance so far. Copying weights to 'model/best.th'.\n",
            "2018-07-18 04:48:09,996 - INFO - allennlp.training.trainer - Training accuracy3 : 1.000000    Validation accuracy3 : 1.000000 \n",
            "2018-07-18 04:48:09,997 - INFO - allennlp.training.trainer - Training accuracy : 0.635000    Validation accuracy : 0.751000 \n",
            "2018-07-18 04:48:09,998 - INFO - allennlp.training.trainer - Training loss : 0.783949    Validation loss : 0.607696 \n",
            "2018-07-18 04:48:09,998 - INFO - allennlp.training.trainer - Epoch duration: 00:00:39\n",
            "2018-07-18 04:48:09,998 - INFO - allennlp.training.trainer - Estimated training time remaining: 00:25:22\n",
            "2018-07-18 04:48:09,999 - INFO - allennlp.training.trainer - Epoch 1/39\n",
            "2018-07-18 04:48:09,999 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 3063.132\n",
            "2018-07-18 04:48:10,090 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 1192\n",
            "  0%|          | 0/235 [00:00<?, ?it/s]2018-07-18 04:48:10,092 - INFO - allennlp.training.trainer - Training\n",
            "accuracy: 0.7746, accuracy3: 1.0000, loss: 0.5700 ||:  12%|#1        | 28/235 [00:04<00:29,  6.92it/s]"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
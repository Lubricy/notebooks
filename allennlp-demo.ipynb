{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Forms",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/Lubricy/notebooks/blob/master/allennlp-demo.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "h9aZYKhly2h_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "82b7519b-20ff-41d2-de44-bdec7e047591"
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/allenai/allennlp-as-a-library-example"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Jul 18 04:27:12 2018       \r\n",
            "+-----------------------------------------------------------------------------+\r\n",
            "| NVIDIA-SMI 384.111                Driver Version: 384.111                   |\r\n",
            "|-------------------------------+----------------------+----------------------+\r\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
            "|===============================+======================+======================|\r\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\r\n",
            "| N/A   31C    P8    29W / 149W |      1MiB / 11439MiB |      0%      Default |\r\n",
            "+-------------------------------+----------------------+----------------------+\r\n",
            "                                                                               \r\n",
            "+-----------------------------------------------------------------------------+\r\n",
            "| Processes:                                                       GPU Memory |\r\n",
            "|  GPU       PID   Type   Process name                             Usage      |\r\n",
            "|=============================================================================|\r\n",
            "|  No running processes found                                                 |\r\n",
            "+-----------------------------------------------------------------------------+\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "j_qv03kVnhch",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d8f9160a-8fed-4acd-898f-7d5e040af748"
      },
      "cell_type": "code",
      "source": [
        "cd allennlp-as-a-library-example/"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/allennlp-as-a-library-example\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XbqI3XaMoA2-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3488
        },
        "outputId": "4ddb36b3-b315-41d0-a5e5-d0fed397849e"
      },
      "cell_type": "code",
      "source": [
        "!rm -r model\n",
        "!allennlp train experiments/venue_classifier.json -s model --include-package my_library"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\r\n",
            "  \"\"\")\r\n",
            "/usr/local/lib/python3.6/dist-packages/allennlp/service/predictors/__init__.py:24: FutureWarning: allennlp.service.predictors.* has been depreciated. Please use allennlp.predictors.*\r\n",
            "  \"Please use allennlp.predictors.*\", FutureWarning)\r\n",
            "/usr/local/lib/python3.6/dist-packages/allennlp/service/predictors/predictor.py:6: FutureWarning: allennlp.service.predictors.* has been deprecated. Please use allennlp.predictors.*\r\n",
            "  \" Please use allennlp.predictors.*\", FutureWarning)\n",
            "2018-07-18 04:28:01,590 - INFO - allennlp.common.params - random_seed = 13370\n",
            "2018-07-18 04:28:01,590 - INFO - allennlp.common.params - numpy_seed = 1337\n",
            "2018-07-18 04:28:01,591 - INFO - allennlp.common.params - pytorch_seed = 133\n",
            "2018-07-18 04:28:01,592 - INFO - allennlp.common.checks - Pytorch version: 0.4.0\n",
            "2018-07-18 04:28:01,595 - INFO - allennlp.common.params - dataset_reader.type = s2_papers\n",
            "2018-07-18 04:28:01,596 - INFO - allennlp.common.params - dataset_reader.lazy = False\n",
            "2018-07-18 04:28:01,596 - INFO - allennlp.common.params - dataset_reader.tokenizer.type = word\n",
            "2018-07-18 04:28:01,596 - INFO - allennlp.common.params - dataset_reader.tokenizer.word_splitter.type = spacy\n",
            "2018-07-18 04:28:01,596 - INFO - allennlp.common.params - dataset_reader.tokenizer.word_splitter.language = en_core_web_sm\n",
            "2018-07-18 04:28:01,596 - INFO - allennlp.common.params - dataset_reader.tokenizer.word_splitter.pos_tags = False\n",
            "2018-07-18 04:28:01,596 - INFO - allennlp.common.params - dataset_reader.tokenizer.word_splitter.parse = False\n",
            "2018-07-18 04:28:01,597 - INFO - allennlp.common.params - dataset_reader.tokenizer.word_splitter.ner = False\n",
            "2018-07-18 04:28:02,033 - INFO - allennlp.common.params - dataset_reader.tokenizer.word_filter.type = pass_through\n",
            "2018-07-18 04:28:02,033 - INFO - allennlp.common.params - dataset_reader.tokenizer.word_stemmer.type = pass_through\n",
            "2018-07-18 04:28:02,033 - INFO - allennlp.common.params - dataset_reader.tokenizer.start_tokens = None\n",
            "2018-07-18 04:28:02,034 - INFO - allennlp.common.params - dataset_reader.tokenizer.end_tokens = None\n",
            "2018-07-18 04:28:02,034 - INFO - allennlp.common.params - validation_dataset_reader = None\n",
            "2018-07-18 04:28:02,034 - INFO - allennlp.common.params - train_data_path = https://s3-us-west-2.amazonaws.com/allennlp/datasets/academic-papers-example/train.jsonl\n",
            "2018-07-18 04:28:02,034 - INFO - allennlp.commands.train - Reading training data from https://s3-us-west-2.amazonaws.com/allennlp/datasets/academic-papers-example/train.jsonl\n",
            "0it [00:00, ?it/s]2018-07-18 04:28:02,272 - INFO - my_library.dataset_readers.semantic_scholar_papers - Reading instances from lines in file at: https://s3-us-west-2.amazonaws.com/allennlp/datasets/academic-papers-example/train.jsonl\n",
            "524it [00:03, 154.21it/s]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15000it [01:32, 162.60it/s]\n",
            "2018-07-18 04:29:34,286 - INFO - allennlp.common.params - validation_data_path = https://s3-us-west-2.amazonaws.com/allennlp/datasets/academic-papers-example/dev.jsonl\n",
            "2018-07-18 04:29:34,286 - INFO - allennlp.commands.train - Reading validation data from https://s3-us-west-2.amazonaws.com/allennlp/datasets/academic-papers-example/dev.jsonl\n",
            "0it [00:00, ?it/s]2018-07-18 04:29:34,528 - INFO - my_library.dataset_readers.semantic_scholar_papers - Reading instances from lines in file at: https://s3-us-west-2.amazonaws.com/allennlp/datasets/academic-papers-example/dev.jsonl\n",
            "2000it [00:12, 165.94it/s]\n",
            "2018-07-18 04:29:46,340 - INFO - allennlp.common.params - test_data_path = None\n",
            "2018-07-18 04:29:46,340 - INFO - allennlp.commands.train - Creating a vocabulary using validation, train data.\n",
            "2018-07-18 04:29:46,340 - INFO - allennlp.common.params - vocabulary.directory_path = None\n",
            "2018-07-18 04:29:46,340 - INFO - allennlp.common.params - vocabulary.min_count = None\n",
            "2018-07-18 04:29:46,340 - INFO - allennlp.common.params - vocabulary.max_vocab_size = None\n",
            "2018-07-18 04:29:46,341 - INFO - allennlp.common.params - vocabulary.non_padded_namespaces = ('*tags', '*labels')\n",
            "2018-07-18 04:29:46,341 - INFO - allennlp.common.params - vocabulary.only_include_pretrained_words = False\n",
            "2018-07-18 04:29:46,341 - INFO - allennlp.common.params - vocabulary.tokens_to_add = None\n",
            "2018-07-18 04:29:46,341 - INFO - allennlp.data.vocabulary - Fitting token dictionary from dataset.\n",
            "1038it [00:00, 2068.45it/s]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "17000it [00:08, 2012.14it/s]\n",
            "2018-07-18 04:29:55,167 - INFO - allennlp.common.params - model.type = paper_classifier\n",
            "2018-07-18 04:29:55,168 - INFO - allennlp.common.params - model.text_field_embedder.type = basic\n",
            "2018-07-18 04:29:55,168 - INFO - allennlp.common.params - model.text_field_embedder.embedder_to_indexer_map = None\n",
            "2018-07-18 04:29:55,168 - INFO - allennlp.common.params - model.text_field_embedder.tokens.type = embedding\n",
            "2018-07-18 04:29:55,168 - INFO - allennlp.common.params - model.text_field_embedder.tokens.num_embeddings = None\n",
            "2018-07-18 04:29:55,169 - INFO - allennlp.common.params - model.text_field_embedder.tokens.vocab_namespace = tokens\n",
            "2018-07-18 04:29:55,169 - INFO - allennlp.common.params - model.text_field_embedder.tokens.embedding_dim = 100\n",
            "2018-07-18 04:29:55,169 - INFO - allennlp.common.params - model.text_field_embedder.tokens.pretrained_file = https://s3-us-west-2.amazonaws.com/allennlp/datasets/glove/glove.6B.100d.txt.gz\n",
            "2018-07-18 04:29:55,169 - INFO - allennlp.common.params - model.text_field_embedder.tokens.projection_dim = None\n",
            "2018-07-18 04:29:55,169 - INFO - allennlp.common.params - model.text_field_embedder.tokens.trainable = False\n",
            "2018-07-18 04:29:55,170 - INFO - allennlp.common.params - model.text_field_embedder.tokens.padding_index = None\n",
            "2018-07-18 04:29:55,170 - INFO - allennlp.common.params - model.text_field_embedder.tokens.max_norm = None\n",
            "2018-07-18 04:29:55,170 - INFO - allennlp.common.params - model.text_field_embedder.tokens.norm_type = 2.0\n",
            "2018-07-18 04:29:55,170 - INFO - allennlp.common.params - model.text_field_embedder.tokens.scale_grad_by_freq = False\n",
            "2018-07-18 04:29:55,170 - INFO - allennlp.common.params - model.text_field_embedder.tokens.sparse = False\n",
            "2018-07-18 04:29:55,177 - INFO - allennlp.modules.token_embedders.embedding - Reading embeddings from file\n",
            "2018-07-18 04:30:02,864 - INFO - allennlp.modules.token_embedders.embedding - Initializing pre-trained embedding layer\n",
            "2018-07-18 04:30:03,190 - INFO - allennlp.common.params - model.title_encoder.type = lstm\n",
            "2018-07-18 04:30:03,190 - INFO - allennlp.common.params - model.title_encoder.batch_first = True\n",
            "2018-07-18 04:30:03,190 - INFO - allennlp.common.params - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n",
            "2018-07-18 04:30:03,190 - INFO - allennlp.common.params - CURRENTLY DEFINED PARAMETERS: \n",
            "2018-07-18 04:30:03,191 - INFO - allennlp.common.params - model.title_encoder.bidirectional = True\n",
            "2018-07-18 04:30:03,191 - INFO - allennlp.common.params - model.title_encoder.input_size = 100\n",
            "2018-07-18 04:30:03,191 - INFO - allennlp.common.params - model.title_encoder.hidden_size = 100\n",
            "2018-07-18 04:30:03,191 - INFO - allennlp.common.params - model.title_encoder.num_layers = 1\n",
            "2018-07-18 04:30:03,191 - INFO - allennlp.common.params - model.title_encoder.dropout = 0.2\n",
            "2018-07-18 04:30:03,191 - INFO - allennlp.common.params - model.title_encoder.batch_first = True\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:38: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "2018-07-18 04:30:03,194 - INFO - allennlp.common.params - model.abstract_encoder.type = lstm\n",
            "2018-07-18 04:30:03,195 - INFO - allennlp.common.params - model.abstract_encoder.batch_first = True\n",
            "2018-07-18 04:30:03,195 - INFO - allennlp.common.params - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n",
            "2018-07-18 04:30:03,195 - INFO - allennlp.common.params - CURRENTLY DEFINED PARAMETERS: \n",
            "2018-07-18 04:30:03,195 - INFO - allennlp.common.params - model.abstract_encoder.bidirectional = True\n",
            "2018-07-18 04:30:03,195 - INFO - allennlp.common.params - model.abstract_encoder.input_size = 100\n",
            "2018-07-18 04:30:03,195 - INFO - allennlp.common.params - model.abstract_encoder.hidden_size = 100\n",
            "2018-07-18 04:30:03,196 - INFO - allennlp.common.params - model.abstract_encoder.num_layers = 1\n",
            "2018-07-18 04:30:03,196 - INFO - allennlp.common.params - model.abstract_encoder.dropout = 0.2\n",
            "2018-07-18 04:30:03,196 - INFO - allennlp.common.params - model.abstract_encoder.batch_first = True\n",
            "2018-07-18 04:30:03,198 - INFO - allennlp.common.params - model.classifier_feedforward.input_dim = 400\n",
            "2018-07-18 04:30:03,198 - INFO - allennlp.common.params - model.classifier_feedforward.num_layers = 2\n",
            "2018-07-18 04:30:03,199 - INFO - allennlp.common.params - model.classifier_feedforward.hidden_dims = [200, 3]\n",
            "2018-07-18 04:30:03,199 - INFO - allennlp.common.params - model.classifier_feedforward.activations = ['relu', 'linear']\n",
            "2018-07-18 04:30:03,199 - INFO - allennlp.common.params - model.classifier_feedforward.dropout = [0.2, 0.0]\n",
            "2018-07-18 04:30:03,201 - INFO - allennlp.common.params - model.initializer = []\n",
            "2018-07-18 04:30:03,201 - INFO - allennlp.common.params - model.regularizer = []\n",
            "2018-07-18 04:30:03,201 - INFO - allennlp.nn.initializers - Initializing parameters\n",
            "2018-07-18 04:30:03,201 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
            "2018-07-18 04:30:03,202 - INFO - allennlp.nn.initializers -    abstract_encoder._module.bias_hh_l0\n",
            "2018-07-18 04:30:03,202 - INFO - allennlp.nn.initializers -    abstract_encoder._module.bias_hh_l0_reverse\n",
            "2018-07-18 04:30:03,202 - INFO - allennlp.nn.initializers -    abstract_encoder._module.bias_ih_l0\n",
            "2018-07-18 04:30:03,202 - INFO - allennlp.nn.initializers -    abstract_encoder._module.bias_ih_l0_reverse\n",
            "2018-07-18 04:30:03,202 - INFO - allennlp.nn.initializers -    abstract_encoder._module.weight_hh_l0\n",
            "2018-07-18 04:30:03,202 - INFO - allennlp.nn.initializers -    abstract_encoder._module.weight_hh_l0_reverse\n",
            "2018-07-18 04:30:03,203 - INFO - allennlp.nn.initializers -    abstract_encoder._module.weight_ih_l0\n",
            "2018-07-18 04:30:03,203 - INFO - allennlp.nn.initializers -    abstract_encoder._module.weight_ih_l0_reverse\n",
            "2018-07-18 04:30:03,203 - INFO - allennlp.nn.initializers -    classifier_feedforward._linear_layers.0.bias\n",
            "2018-07-18 04:30:03,203 - INFO - allennlp.nn.initializers -    classifier_feedforward._linear_layers.0.weight\n",
            "2018-07-18 04:30:03,203 - INFO - allennlp.nn.initializers -    classifier_feedforward._linear_layers.1.bias\n",
            "2018-07-18 04:30:03,203 - INFO - allennlp.nn.initializers -    classifier_feedforward._linear_layers.1.weight\n",
            "2018-07-18 04:30:03,204 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_tokens.weight\n",
            "2018-07-18 04:30:03,204 - INFO - allennlp.nn.initializers -    title_encoder._module.bias_hh_l0\n",
            "2018-07-18 04:30:03,204 - INFO - allennlp.nn.initializers -    title_encoder._module.bias_hh_l0_reverse\n",
            "2018-07-18 04:30:03,204 - INFO - allennlp.nn.initializers -    title_encoder._module.bias_ih_l0\n",
            "2018-07-18 04:30:03,204 - INFO - allennlp.nn.initializers -    title_encoder._module.bias_ih_l0_reverse\n",
            "2018-07-18 04:30:03,204 - INFO - allennlp.nn.initializers -    title_encoder._module.weight_hh_l0\n",
            "2018-07-18 04:30:03,205 - INFO - allennlp.nn.initializers -    title_encoder._module.weight_hh_l0_reverse\n",
            "2018-07-18 04:30:03,205 - INFO - allennlp.nn.initializers -    title_encoder._module.weight_ih_l0\n",
            "2018-07-18 04:30:03,205 - INFO - allennlp.nn.initializers -    title_encoder._module.weight_ih_l0_reverse\n",
            "2018-07-18 04:30:03,205 - INFO - allennlp.common.params - iterator.type = bucket\n",
            "2018-07-18 04:30:03,206 - INFO - allennlp.common.params - iterator.sorting_keys = [['abstract', 'num_tokens'], ['title', 'num_tokens']]\n",
            "2018-07-18 04:30:03,206 - INFO - allennlp.common.params - iterator.padding_noise = 0.1\n",
            "2018-07-18 04:30:03,206 - INFO - allennlp.common.params - iterator.biggest_batch_first = False\n",
            "2018-07-18 04:30:03,206 - INFO - allennlp.common.params - iterator.batch_size = 64\n",
            "2018-07-18 04:30:03,206 - INFO - allennlp.common.params - iterator.instances_per_epoch = None\n",
            "2018-07-18 04:30:03,207 - INFO - allennlp.common.params - iterator.max_instances_in_memory = None\n",
            "2018-07-18 04:30:03,207 - INFO - allennlp.common.params - trainer.patience = 10\n",
            "2018-07-18 04:30:03,207 - INFO - allennlp.common.params - trainer.validation_metric = +accuracy\n",
            "2018-07-18 04:30:03,207 - INFO - allennlp.common.params - trainer.num_epochs = 40\n",
            "2018-07-18 04:30:03,208 - INFO - allennlp.common.params - trainer.cuda_device = 0\n",
            "2018-07-18 04:30:03,208 - INFO - allennlp.common.params - trainer.grad_norm = None\n",
            "2018-07-18 04:30:03,208 - INFO - allennlp.common.params - trainer.grad_clipping = 5.0\n",
            "2018-07-18 04:30:03,208 - INFO - allennlp.common.params - trainer.learning_rate_scheduler = None\n",
            "2018-07-18 04:30:07,152 - INFO - allennlp.common.params - trainer.optimizer.type = adagrad\n",
            "2018-07-18 04:30:07,152 - INFO - allennlp.common.params - trainer.optimizer.parameter_groups = None\n",
            "2018-07-18 04:30:07,152 - INFO - allennlp.common.params - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n",
            "2018-07-18 04:30:07,152 - INFO - allennlp.common.params - CURRENTLY DEFINED PARAMETERS: \n",
            "2018-07-18 04:30:07,154 - INFO - allennlp.common.params - trainer.num_serialized_models_to_keep = None\n",
            "2018-07-18 04:30:07,154 - INFO - allennlp.common.params - trainer.keep_serialized_model_every_num_seconds = None\n",
            "2018-07-18 04:30:07,155 - INFO - allennlp.common.params - trainer.model_save_interval = None\n",
            "2018-07-18 04:30:07,155 - INFO - allennlp.common.params - trainer.summary_interval = 100\n",
            "2018-07-18 04:30:07,155 - INFO - allennlp.common.params - trainer.histogram_interval = None\n",
            "2018-07-18 04:30:07,159 - INFO - allennlp.common.params - evaluate_on_test = False\n",
            "2018-07-18 04:30:07,160 - INFO - allennlp.training.trainer - Beginning training.\n",
            "2018-07-18 04:30:07,160 - INFO - allennlp.training.trainer - Epoch 0/39\n",
            "2018-07-18 04:30:07,160 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 2902.852\n",
            "2018-07-18 04:30:07,246 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 350\n",
            "  0%|          | 0/235 [00:00<?, ?it/s]2018-07-18 04:30:07,248 - INFO - allennlp.training.trainer - Training\n",
            "accuracy: 0.4062, accuracy3: 1.0000, loss: 1.1358 ||:   3%|3         | 8/235 [00:11<05:26,  1.44s/it]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy: 0.6350, accuracy3: 1.0000, loss: 0.7839 ||: 100%|##########| 235/235 [00:35<00:00,  6.71it/s]\n",
            "2018-07-18 04:30:42,251 - INFO - allennlp.training.trainer - Validating\n",
            "accuracy: 0.7510, accuracy3: 1.0000, loss: 0.6077 ||: 100%|##########| 32/32 [00:03<00:00,  9.18it/s]\n",
            "2018-07-18 04:30:45,901 - INFO - allennlp.training.trainer - Best validation performance so far. Copying weights to 'model/best.th'.\n",
            "2018-07-18 04:30:45,945 - INFO - allennlp.training.trainer - Training loss : 0.783949    Validation loss : 0.607696 \n",
            "2018-07-18 04:30:45,945 - INFO - allennlp.training.trainer - Training accuracy3 : 1.000000    Validation accuracy3 : 1.000000 \n",
            "2018-07-18 04:30:45,945 - INFO - allennlp.training.trainer - Training accuracy : 0.635000    Validation accuracy : 0.751000 \n",
            "2018-07-18 04:30:45,946 - INFO - allennlp.training.trainer - Epoch duration: 00:00:38\n",
            "2018-07-18 04:30:45,947 - INFO - allennlp.training.trainer - Estimated training time remaining: 00:25:12\n",
            "2018-07-18 04:30:45,947 - INFO - allennlp.training.trainer - Epoch 1/39\n",
            "2018-07-18 04:30:45,947 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 3064.568\n",
            "2018-07-18 04:30:46,038 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 1192\n",
            "  0%|          | 0/235 [00:00<?, ?it/s]2018-07-18 04:30:46,040 - INFO - allennlp.training.trainer - Training\n",
            "accuracy: 0.7614, accuracy3: 1.0000, loss: 0.5821 ||:  43%|####2     | 101/235 [00:11<00:15,  8.70it/s]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy: 0.7753, accuracy3: 1.0000, loss: 0.5513 ||: 100%|##########| 235/235 [00:25<00:00,  9.04it/s]\n",
            "2018-07-18 04:31:12,038 - INFO - allennlp.training.trainer - Validating\n",
            "accuracy: 0.7795, accuracy3: 1.0000, loss: 0.5498 ||: 100%|##########| 32/32 [00:02<00:00, 13.45it/s]\n",
            "2018-07-18 04:31:14,473 - INFO - allennlp.training.trainer - Best validation performance so far. Copying weights to 'model/best.th'.\n",
            "2018-07-18 04:31:14,529 - INFO - allennlp.training.trainer - Training loss : 0.551275    Validation loss : 0.549829 \n",
            "2018-07-18 04:31:14,530 - INFO - allennlp.training.trainer - Training accuracy3 : 1.000000    Validation accuracy3 : 1.000000 \n",
            "2018-07-18 04:31:14,531 - INFO - allennlp.training.trainer - Training accuracy : 0.775267    Validation accuracy : 0.779500 \n",
            "2018-07-18 04:31:14,531 - INFO - allennlp.training.trainer - Epoch duration: 00:00:28\n",
            "2018-07-18 04:31:14,532 - INFO - allennlp.training.trainer - Estimated training time remaining: 00:21:20\n",
            "2018-07-18 04:31:14,532 - INFO - allennlp.training.trainer - Epoch 2/39\n",
            "2018-07-18 04:31:14,532 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 3091.18\n",
            "2018-07-18 04:31:14,627 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 1405\n",
            "  0%|          | 0/235 [00:00<?, ?it/s]2018-07-18 04:31:14,628 - INFO - allennlp.training.trainer - Training\n",
            "accuracy: 0.8087, accuracy3: 1.0000, loss: 0.4806 ||:  44%|####4     | 104/235 [00:12<00:15,  8.38it/s]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy: 0.8105, accuracy3: 1.0000, loss: 0.4816 ||: 100%|##########| 235/235 [00:26<00:00,  8.99it/s]\n",
            "2018-07-18 04:31:40,761 - INFO - allennlp.training.trainer - Validating\n",
            "accuracy: 0.7630, accuracy3: 1.0000, loss: 0.5823 ||: 100%|##########| 32/32 [00:02<00:00, 13.47it/s]\n",
            "2018-07-18 04:31:43,181 - INFO - allennlp.training.trainer - Training loss : 0.481595    Validation loss : 0.582266 \n",
            "2018-07-18 04:31:43,182 - INFO - allennlp.training.trainer - Training accuracy3 : 1.000000    Validation accuracy3 : 1.000000 \n",
            "2018-07-18 04:31:43,183 - INFO - allennlp.training.trainer - Training accuracy : 0.810533    Validation accuracy : 0.763000 \n",
            "2018-07-18 04:31:43,183 - INFO - allennlp.training.trainer - Epoch duration: 00:00:28\n",
            "2018-07-18 04:31:43,183 - INFO - allennlp.training.trainer - Estimated training time remaining: 00:19:44\n",
            "2018-07-18 04:31:43,183 - INFO - allennlp.training.trainer - Epoch 3/39\n",
            "2018-07-18 04:31:43,184 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 3091.304\n",
            "2018-07-18 04:31:43,278 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 1405\n",
            "  0%|          | 0/235 [00:00<?, ?it/s]2018-07-18 04:31:43,280 - INFO - allennlp.training.trainer - Training\n",
            "accuracy: 0.8218, accuracy3: 1.0000, loss: 0.4429 ||:  43%|####3     | 102/235 [00:12<00:15,  8.43it/s]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy: 0.8273, accuracy3: 1.0000, loss: 0.4362 ||: 100%|##########| 235/235 [00:25<00:00,  9.08it/s]\n",
            "2018-07-18 04:32:09,167 - INFO - allennlp.training.trainer - Validating\n",
            "accuracy: 0.7960, accuracy3: 1.0000, loss: 0.5214 ||: 100%|##########| 32/32 [00:02<00:00, 13.68it/s]\n",
            "2018-07-18 04:32:11,549 - INFO - allennlp.training.trainer - Best validation performance so far. Copying weights to 'model/best.th'.\n",
            "2018-07-18 04:32:11,606 - INFO - allennlp.training.trainer - Training loss : 0.436166    Validation loss : 0.521363 \n",
            "2018-07-18 04:32:11,606 - INFO - allennlp.training.trainer - Training accuracy3 : 1.000000    Validation accuracy3 : 1.000000 \n",
            "2018-07-18 04:32:11,607 - INFO - allennlp.training.trainer - Training accuracy : 0.827333    Validation accuracy : 0.796000 \n",
            "2018-07-18 04:32:11,607 - INFO - allennlp.training.trainer - Epoch duration: 00:00:28\n",
            "2018-07-18 04:32:11,607 - INFO - allennlp.training.trainer - Estimated training time remaining: 00:18:40\n",
            "2018-07-18 04:32:11,607 - INFO - allennlp.training.trainer - Epoch 4/39\n",
            "2018-07-18 04:32:11,607 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 3091.308\n",
            "2018-07-18 04:32:11,704 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 1405\n",
            "  0%|          | 0/235 [00:00<?, ?it/s]2018-07-18 04:32:11,705 - INFO - allennlp.training.trainer - Training\n",
            "accuracy: 0.8500, accuracy3: 1.0000, loss: 0.3854 ||:  40%|####      | 95/235 [00:10<00:16,  8.66it/s]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy: 0.8462, accuracy3: 1.0000, loss: 0.3939 ||: 100%|##########| 235/235 [00:25<00:00,  9.05it/s]\n",
            "2018-07-18 04:32:37,668 - INFO - allennlp.training.trainer - Validating\n",
            "accuracy: 0.7920, accuracy3: 1.0000, loss: 0.5344 ||: 100%|##########| 32/32 [00:02<00:00, 13.65it/s]\n",
            "2018-07-18 04:32:40,055 - INFO - allennlp.training.trainer - Training loss : 0.393947    Validation loss : 0.534397 \n",
            "2018-07-18 04:32:40,056 - INFO - allennlp.training.trainer - Training accuracy3 : 1.000000    Validation accuracy3 : 1.000000 \n",
            "2018-07-18 04:32:40,056 - INFO - allennlp.training.trainer - Training accuracy : 0.846200    Validation accuracy : 0.792000 \n",
            "2018-07-18 04:32:40,057 - INFO - allennlp.training.trainer - Epoch duration: 00:00:28\n",
            "2018-07-18 04:32:40,057 - INFO - allennlp.training.trainer - Estimated training time remaining: 00:17:50\n",
            "2018-07-18 04:32:40,057 - INFO - allennlp.training.trainer - Epoch 5/39\n",
            "2018-07-18 04:32:40,058 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 3091.32\n",
            "2018-07-18 04:32:40,149 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 1405\n",
            "  0%|          | 0/235 [00:00<?, ?it/s]2018-07-18 04:32:40,150 - INFO - allennlp.training.trainer - Training\n",
            "accuracy: 0.8551, accuracy3: 1.0000, loss: 0.3648 ||:  17%|#7        | 40/235 [00:05<00:24,  7.90it/s]"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}